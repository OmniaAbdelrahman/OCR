{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3aba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "img = cv2.imread('C:/Users/omnia.abdelrahman/Pictures/OCR/Combining+EAST+and+CRNN/OCR_LNP.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23afedeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dnn_Net 00000124764CD1B0>\n",
      "<dnn_Net 00000124764CD0B0>\n"
     ]
    }
   ],
   "source": [
    "## -------------  Load the pre-trained models ---------------\n",
    "model = cv2.dnn.readNet('C:/Users/omnia.abdelrahman/Pictures/OCR/Combining+EAST+and+CRNN/frozen_east_text_detection.pb')\n",
    "model1 = cv2.dnn.readNet('C:/Users/omnia.abdelrahman/Pictures/OCR/Combining+EAST+and+CRNN/crnn.onnx')\n",
    "print(model)\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc81a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_height:  480  , new_width:  352\n",
      "h_ratio:  1.025  , w_ratio:  1.0227272727272727\n"
     ]
    }
   ],
   "source": [
    "## -------------  Prepare the image  ----------------\n",
    "# use multiple of 32 to set the new img shape\n",
    "height, width, _ = img.shape\n",
    "new_height = (height//32)*32\n",
    "new_width = (width//32)*32\n",
    "print('new_height: ',new_height,' , new_width: ', new_width)\n",
    "\n",
    "# get the ratio change in width and height\n",
    "h_ratio = height/new_height\n",
    "w_ratio = width/new_width\n",
    "print('h_ratio: ',h_ratio,' , w_ratio: ', w_ratio)\n",
    "\n",
    "# It returns a 4-dimensional array/blob for the input image.\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (new_width, new_height),(123.68, 116.78, 103.94), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d48257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------  Forward Propagation  -------------\n",
    "model.setInput(blob)\n",
    "(geometry, scores) = model.forward(model.getUnconnectedOutLayersNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9e5122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 120, 88)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0dbcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 120, 88)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d580ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------   Post-Processing  ----------------\n",
    "rectangles = []\n",
    "confidence_score = []\n",
    "for i in range(geometry.shape[2]):\n",
    "    for j in range(0, geometry.shape[3]):\n",
    "        \n",
    "        if scores[0][0][i][j] < 0.1:\n",
    "            continue\n",
    "            \n",
    "        bottom_x = int(j*4 + geometry[0][1][i][j])\n",
    "        bottom_y = int(i*4 + geometry[0][2][i][j])\n",
    "        \n",
    "\n",
    "        top_x = int(j*4 - geometry[0][3][i][j])\n",
    "        top_y = int(i*4 - geometry[0][0][i][j])\n",
    "        \n",
    "        rectangles.append((top_x, top_y, bottom_x, bottom_y))\n",
    "        confidence_score.append(float(scores[0][0][i][j]))\n",
    "\n",
    "# use Non-max suppression to get the required rectangles\n",
    "fin_boxes = non_max_suppression(np.array(rectangles), probs=confidence_score, overlapThresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6b2459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142, 368, 198, 391],\n",
       "       [ 67, 109, 188, 134],\n",
       "       [ 69, 324, 218, 352],\n",
       "       [ 91,  67, 188,  91],\n",
       "       [197, 110, 270, 134],\n",
       "       [223, 324, 272, 349],\n",
       "       [197,  67, 245,  91]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6cd1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --------------- Load the CRNN decoding functions -------------\n",
    "def most_likely(scores, char_set):\n",
    "    text = \"\"\n",
    "    for i in range(scores.shape[0]):\n",
    "        c = np.argmax(scores[i][0])\n",
    "        text += char_set[c]\n",
    "    return text\n",
    "\n",
    "def map_rule(text):\n",
    "    char_list = []\n",
    "    for i in range(len(text)):\n",
    "        if i == 0:\n",
    "            if text[i] != '-':\n",
    "                char_list.append(text[i])\n",
    "        else:\n",
    "            if text[i] != '-' and (not (text[i] == text[i - 1])):\n",
    "                char_list.append(text[i])\n",
    "    return ''.join(char_list)\n",
    "\n",
    "def best_path(scores, char_set):\n",
    "    text = most_likely(scores, char_set)\n",
    "    final_text = map_rule(text)\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f186405",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_set = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "blank = '-'\n",
    "\n",
    "char_set = blank + alphabet_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30b1bf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ---------------  Recognize the text using CRNN in each segment -----------\n",
    "img_copy = img.copy()\n",
    "for (x1, y1, x2, y2) in fin_boxes:\n",
    "\n",
    "    x1 = int(x1 * w_ratio)\n",
    "    y1 = int(y1 * h_ratio)\n",
    "    x2 = int(x2 * w_ratio)\n",
    "    y2 = int(y2 * h_ratio)\n",
    "    \n",
    "    segment = img[y1:y2, x1:x2, :]\n",
    "    \n",
    "    segment_gray = cv2.cvtColor(segment, cv2.COLOR_BGR2GRAY)\n",
    "    blob = cv2.dnn.blobFromImage(segment_gray, scalefactor=1/127.5, size=(100,32), mean=127.5)\n",
    "    \n",
    "    model1.setInput(blob)\n",
    "    scores = model1.forward()\n",
    "    text = best_path(scores, char_set)\n",
    "\n",
    "    cv2.rectangle(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img_copy, text.strip(), (x1,y1-2), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0,0,255),2)\n",
    "\n",
    "cv2.imshow(\"Text Detection\", img_copy)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_env",
   "language": "python",
   "name": "img_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
